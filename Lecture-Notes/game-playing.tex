\chapter{Playing Games}
One major success for the field of artificial intelligence happened in 1997 when the chess-playing computer
\href{https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)}{Deep Blue} was able to beat the World Chess
Champion \href{https://en.wikipedia.org/wiki/Garry_Kasparov}{Garry Kasparov} by $3\sfrac{1}{2}-2\sfrac{1}{2}$.
While \emph{\color{blue}Deep Blue} was based on special hardware, today according to the
\href{http://www.computerchess.org.uk/ccrl/4040/rating_list_all.html}{computer chess rating list} 
top performing chess programs like \href{https://en.wikipedia.org/wiki/Stockfish_(chess)}{Stockfish} have an 
\href{https://en.wikipedia.org/wiki/Elo_rating_system}{Elo rating} of 3392.  To compare, according to 
\href{https://ratings.fide.com/top.phtml?list=men}{Fide}, the current 
World Chess Champion \href{https://en.wikipedia.org/wiki/Magnus_Carlsen}{Magnus Carlsen} has an Elo rating of
just 2838.  Hence, he wouldn't stand a chance to win a game against Stockfish.  More recently, the computer program
\href{https://en.wikipedia.org/wiki/AlphaGo}{AlphaGo} was able to beat
\href{https://en.wikipedia.org/wiki/Lee_Sedol}{Lee Sedol}, who is considered to be the second best 
\href{https://en.wikipedia.org/wiki/Go_(game)}{go} player in the world.  Besides go and chess, there are many
other games where today the performance of a computer exceeds the performance of human players.  To name just
one more example, at the beginning of 2017 the program \href{https://en.wikipedia.org/wiki/Libratus}{Libratus} was able to 
\href{https://www.engadget.com/2017/01/31/libratus-the-poker-playing-ai-destroyed-its-four-human-rivals/}{beat}
four professional poker players resoundingly.

In this chapter we want to investigate how a computer can play a game.  To this end we define a
\blue{game} $\mathcal{G}$ as a six-tuple
\\[0.2cm]
\hspace*{1.3cm}
$\mathcal{G} = \langle \mathtt{States}, s_0, \mathtt{Players}, \mathtt{nextStates}, \mathtt{finished},\mathtt{utility} \rangle$
\\[0.2cm]
where the components are interpreted as follows:
\begin{enumerate}
\item $\mathtt{States}$ is the set of all possible \emph{\color{blue}states} of the game.
\item $s_0 \in \mathtt{startState}$ is the \emph{\color{blue}start state}.
\item $\mathtt{Players}$ is  the set of \blue{players} of the game.
\item $\mathtt{nextStates}$ is a function that takes a state and a player $p$ and returns the set of
      states that can be reached if $p$ has to make a move in the game.  Hence, the signature of
      $\mathtt{nextStates}$ is given as follows:
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{nextStates}: \mathtt{State} \times \mathtt{Player} \rightarrow 2^{\mathtt{States}}$.
\item $\mathtt{finished}$ is a function that takes a state $s$ and decides whether the games is finished.
      Therefore
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{finished}: \mathtt{States} \rightarrow \mathbb{B}$.
      \\[0.2cm]
      Here, $\mathbb{B}$ is the set of Boolean values, i.e.~we have $\mathbb{B} := \{ \mathtt{true}, \mathtt{false} \}$.
  
      Using the function $\mathtt{finished}$, we define the set $\mathtt{TerminalStates}$ as the set of those
      states such that the game has finished,  i.e.~we define
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{TerminalStates} := \{ s \in \mathtt{States} \mid \mathtt{finished}(s) \}$.
\item $\mathtt{utility}$ is a function that takes a state $s \in \mathtt{TerminalStates}$ and a player $p$.  If returns
      the \blue{value} that the game has for player $p$.  In all of our examples, this value will be an element
      from the set $\{-1, 0, +1\}$.  The value $-1$ indicates that player $s$ has lost the game,
      if the value is $+1$ the player $p$ has won the game and if this value is $0$ then the game is drawn.
      Hence the signature of $\mathtt{utility}$ is
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{utility}: \mathtt{TerminalStates} \times \mathtt{Players} \rightarrow \{ -1, 0, +1\}$.
\end{enumerate}

\exercise
The definition given above does not capture all types of games.  In particular, the definition only captures 
\blue{deterministic games}:  A game is called \blue{deterministic} iff there is no randomness
involved.  Games like chess and go are certainly deterministic.  However, other games like 
\href{https://en.wikipedia.org/wiki/Dice_chess}{dice chess} involve randomness.  In dice chess a pair of dice is
rolled at the beginning of each turn.  The outcome of this roll determines which pieces may be moved.
Extend the definition of a
game so that also a games like \blue{dice chess} be modelled.  
\eox

In this chapter we will only consider so called \blue{two person zero sum games}.  This means that the set $\mathtt{Players}$
has exactly two elements.  If we call these players $\mathrm{A}$ and $\mathrm{B}$, i.e.~if we have
\\[0.2cm]
\hspace*{1.3cm}
$\mathtt{Players} = \{ \mathrm{A}, \mathrm{B} \}$,
\\[0.2cm]
then the game is called a \blue{zero sum game} iff we have
\\[0.2cm]
\hspace*{1.3cm}
$\forall s \in \mathtt{TerminalStates}:\mathtt{utility}(s, \mathtt{A}) + \mathtt{utility}(s, \mathtt{B}) = 0$,
\\[0.2cm]
i.e.~the losses of player $\mathrm{A}$ are compensated by the wins of player $\mathtt{B}$ and vice versa.
Games like \href{https://en.wikipedia.org/wiki/Go_(game)}{go} and 
\href{https://en.wikipedia.org/wiki/Chess}{chess} are two person zero sum games.

\example
The game \href{https://en.wikipedia.org/wiki/Tic-tac-toe}{tic-tac-toe} is played on a square board of size 
$3 \times 3$.  On every turn, player $\mathrm{A}$ puts an ``\texttt{X}'' on one of the free squares of the board, while
player $\mathrm{B}$ puts an $\mathtt{O}$ onto a free square.  If player $\mathrm{A}$ has three \texttt{X}s in a
row, column, or diagonal, he has won the game.  Similarly, if player $\mathrm{B}$ has three \texttt{O}s in a
row, column, or diagonal, player $\mathrm{B}$ is the winner.  Otherwise, the game is drawn.

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    players := procedure() { return { "X", "O" }; };
    startState := procedure(n) {
        L := [1 .. n];
        return [ [ " " : col in L] : row in L];
    };
    nextStates := procedure(State, player) {
         Empty  := find_empty(State);
        Result := {};
        for ([row, col] in Empty) {
            NextState           := State;
            NextState[row][col] := player;
            Result              += { NextState };
        }
        return Result;
    };
    find_empty := procedure(State) {
        n := #State;
        L := [1 .. n];
        return { [row, col] : row in L, col in L | State[row][col] == " " };
    };
    utility := procedure(State, player) {
        Lines := all_lines(State);
        for (line in Lines) {
            if (#{ x : x in line } == 1 && line != { " " }) {
                if (line == { player }) { return  1; } else { return -1; }
            }
        }
        if (find_empty(State) == {}) { return 0; }
    };
    all_lines := procedure(State) {
        n := #State;
        L := [1 .. n];
        Lines := { { State[row][col] : col in L } : row in L };
        Lines += { { State[row][col] : row in L } : col in L };
        Lines += { { State[idx][idx] : idx in L } };
        Lines += { { State[idx][n - (idx - 1) ] : idx in L } };
        return Lines;
    };
    finished := procedure(State) {
        player := "X";
        if (utility(State, player) != om) { return true; } else { return false; }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{A \textsc{SetlX} description of tic-tac-toe.}
\label{fig:ttt.stlx}
\end{figure}
 
\myFig{ttt.stlx} shows a \textsc{SetlX} implementation of tic-tac-toe.
\begin{enumerate}
\item The function $\mathtt{players}$ returns the set $\mathtt{Players}$.  Traditionally, the players in
      tic-tac-toe are called ``\texttt{X}'' and ``\texttt{O}''.
\item The function $\mathtt{startState}$ returns the start state, which is an empty board.
      States are represented as list of lists.  The entries in these lists are the characters 
      ``\texttt{X}'', ``\texttt{O}'', and ``\texttt{ }''.
      As the  $\mathtt{StartState}$ is the empty board, it is represented as as follows:
      \begin{Verbatim}
      [ [" ", " ", " "], 
        [" ", " ", " "], 
        [" ", " ", " "]
      ].     
      \end{Verbatim}
      The function $\mathtt{startState}$ receives one optional argument $\mathtt{n}$.
      By default $\mathtt{n}$ is equal to $3$.  This argument specifies the size of the board.
      Although traditionally tic-tac-toe is played on a $3 \times 3$ board, it can also 
      be played on a bigger board.
\item The function $\mathtt{nextStates}$ takes a $\mathtt{State}$ and a $\mathtt{player}$ and computes the set
      of states that can be reached from $\mathtt{State}$ if $\mathtt{player}$ is to move next.
      To this end, it first computes the set of \blue{empty} positions.  Every position is represented as pair of the
      form $[\mathtt{row}, \mathtt{col}]$ where $\mathtt{row}$ specifies the row and $\mathtt{col}$ specifies
      the column of the position.  A position is \blue{empty} iff
      \\[0.2cm]
      \hspace*{1.3cm}
      $[\mathtt{row}, \mathtt{col}] = \texttt{\symbol{34}\;\;\symbol{34}}$.
      \\[0.2cm]
      The computation of the empty position has been sourced out to the function $\mathtt{find\_empty}$.
      The function $\mathtt{nextStates}$ then iterates over the set of empty positions. For every 
      empty position $[\mathtt{row}, \mathtt{col}]$ it creates a new state $\mathtt{NextState}$ that results
      from the current $\mathtt{State}$ by putting the mark of $\mathtt{player}$ in this position.  
      The resulting states are collected in the set $\mathtt{Result}$ and returned.
\item The function $\mathtt{find\_empty}$ takes a $\mathtt{State}$ and returns the set of empty positions.
\item The function $\mathtt{utility}$ takes a $\mathtt{State}$ and a $\mathtt{player}$.  If the game is 
      finished in the given $\mathtt{State}$, it returns the value that this $\mathtt{State}$ has for the
      current $\mathtt{player}$.  If the game is not yet decided, $\Omega$ is returned instead.
 
      In order to achieve its goal, the procedure first computes the set of all \blue{lines}.
      Given a $\mathtt{State}$, a \blue{line} is a set of those markers that either form a horizontal,
      vertical, or diagonal line in $\mathtt{State}$, e.g.~the set 
      \\[0.2cm]
      \hspace*{1.3cm}
      $\{ \mathtt{State}[1,1], \mathtt{State}[2,2], \mathtt{State}[3,3] \}$
      \\[0.2cm]
      is the set of entries in a diagonal line.  The game is decided if all entries in this set are either
      ``$\mathtt{X}$'' or ``$\mathtt{O}$''.  In this case, the set has exactly one element which is different
      from the blank.  If this element is the same as $\mathtt{player}$, then the game is won by
      $\mathtt{player}$, otherwise it is lost.

      If there are no empty squares left, then the game is a draw.
\item The auxiliary procedure $\mathtt{all\_lines}$ takes a $\mathtt{State}$ and computes the sets of all
      \blue{lines}. 
\item The procedure $\mathtt{finished}$ takes a $\mathtt{State}$ and checks whether the game is finished.
      To this end it computes the $\mathtt{utility}$ of the state for the player ``$\mathtt{X}$''.  
      If this $\mathtt{utility}$ is different from $\Omega$, the game is finished.  Note that it makes no
      difference whether we take the utility of the state for the player ``$\mathtt{X}$'' or for the player
      ``$\mathtt{O}$'' since if the game is finished for  ``$\mathtt{X}$'' it is also finished for
      ``$\mathtt{O}$'' and vice versa.
\end{enumerate}

\section{The Minimax Algorithm}
Having defined the notion of a game, our next task is to come up with an algorithm that can play a game.  The
easiest algorithm that works is the \href{https://en.wikipedia.org/wiki/Minimax}{minimax algorithm}.  This
algorithm is based on the notion of the \blue{value} of a state.  To this end, we define a function
\\[0.2cm]
\hspace*{1.3cm}
$\mathtt{value}: \mathtt{States} \times \mathtt{player} \rightarrow \{-1, 0, +1\}$
\\[0.2cm]
that takes a state $s$ and a player $p$ and returns the value that $s$ has if both the player $p$ and his
opponent play perfectly.  The easiest way to define this function is via recursion.  The base case is simple:
\\[0.2cm]
\hspace*{1.3cm}
$\mathtt{finished}(s) \rightarrow \mathtt{value}(s, p) = \mathtt{utility}(s, p)$.
\\[0.2cm]
If the game is not yet finished, assume that $o$ is the opponent of $p$.  Then we define
\\[0.2cm]
\hspace*{1.3cm}
$\neg \mathtt{finished}(s) \rightarrow 
 \mathtt{value}(s, p) = \max\bigl(\bigl\{
                     -\mathtt{value}(s, o) \mid n \in \mathtt{nextStates}(s, p)
                     \bigr\}\bigr)
$.
\\[0.2cm]
The reason is that if the game is not finished yet, the player $p$ has to evaluate all possible moves.  
Then the player will choose the best move.  In order to do so, the player computes the set
$\mathtt{nextStates}(s, p)$ of all states that can be reached in one move from the state $s$.
Now if $n$ is a state that results from player $p$ making a move, the other player $o$ has to make his move in
the state $n$.  As we are investigation zero sum games, we have $\mathtt{value}(n, p) = -\mathtt{value}(n, o)$.
\myFig{game.stlx} shows an implementation of this strategy.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    value := cachedProcedure(State, player) {
        if (finished(State)) {
            return utility(State, player);
        }
        other := arb(players() - { player });
        return max({ -value(s, other) : s in nextStates(State, player) });
    };
    best_move := procedure(State, player) {
        AllStates := nextStates(State, player);
        other     := arb(players() - { player });
        bestValue := max({ -value(s, other) : s in AllStates });
        return rnd({ s : s in AllStates | -value(s, other) == bestValue });
    };
    play_game := procedure(n) {
        State := startState(n);
        print(stateToString(State));
        while (true) {
            State := best_move(State, "O");
            print("My move:");
            print(stateToString(State));
            if (final_msg(State)) { return; }
            State := getMove(State);
            print(stateToString(State));
            if (final_msg(State)) { return; }
        }
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{The Minimax algorithm.}
\label{fig:game.stlx}
\end{figure}
\begin{enumerate}
\item The implementation of the function $\mathtt{value}$ follows the reasoning outlined above.
      However, note that we have implemented $\mathtt{value}$ as a $\mathtt{cachedProcedure}$, i.e.~as a
      procedure that memorizes its results.  Hence, when it is called a second time with the same arguments, it
      does not recompute the value but rather the value is looked up.  To understand why this is important,
      let us consider how many states would be explored in the case of tic-tac-toe if we would not use
      \href{https://en.wikipedia.org/wiki/Memoization}{memoization}.  In this case, we have 9 moves for player
      ``\texttt{O}'' from the start state, then 8 moves for player ``\texttt{X}'', then again 7 moves for
      player ``\texttt{X}''.  If we disregard the fact that some games are decided after fewer than 9 moves,
      the function $\mathtt{value}$ needs to consider 
      \\[0.2cm]
      \hspace*{1.3cm}
      $9 \cdot 8 \cdot 7 \cdot {\dots} \cdot 2 \cdot 1 = 9! = 362880$
      \\[0.2cm]
      moves.  However, if we count the number of possibilities of putting 5 ``\texttt{O}''s and 4
      ``\texttt{X}''s on a $3 \times 3$ board, we see that there are only
      \\[0.2cm]
      \hspace*{1.3cm}
      $\ds {9 \choose 5} = \frac{9!}{5! \cdot 4!} = 126$
      \\[0.2cm]
      possibilities, i.e.~there are a factor of $5! \cdot 4! = 2880$ less states to evaluate!
\item The function $\mathtt{best\_move}$ takes a $\mathtt{State}$ and a $\mathtt{player}$ and returns a state $s$
      that is optimal for the $\mathtt{player}$ and such that $s$ can be reached in one step from
      $\mathtt{State}$.  
      \begin{enumerate}[(a)]
      \item To this end, it first computes the set $\mathtt{AllStates}$ of all states that can be reached 
            from the given $\mathtt{State}$ in one step if $\mathtt{player}$ is to move next.
      \item Since there are only two players, $\mathtt{other}$ is the opponent of $\mathtt{player}$.
      \item $\mathtt{bestValue}$ is the best value that $\mathtt{player}$ can achieve.
      \item The function returns randomly one of those states $\mathtt{s} \in \mathtt{AllStates}$ such that 
            the value of $s$ is maximal, i.e.~is equal to $\mathtt{bestValue}$.
      \end{enumerate}
\item The function $\mathtt{play\_game}$ is used to play a game.
      \begin{enumerate}
      \item Since we would prefer to have 
      \item Initially, $\mathtt{State}$ is the $\mathtt{startState}$.
      \item As long as the game is not finished, the procedure keeps running.
      \item We assume that the computer is player ``\texttt{O}'' and that the computer goes first.
            Hence, the function $\mathtt{best\_move}$ is used to compute the state that results from the best
            move of player ``\texttt{O}''.
      \item After that, it is checked whether the game is finished.
      \item If the game is not  yet finished, the human is asked to make its move via the function
            $\mathtt{getMove}$ that takes a $\mathtt{State}$, displays it, and asks the user to enter a move.
            The state resulting from this move is then returned and displayed.
      \item Next, we have to check whether the game has finished.
      \item The \texttt{while}-loop keeps iterating until the game is decided.
      \end{enumerate}
\end{enumerate}

\section{$\alpha$-$\beta$-Pruning}
The minimax algorithm can be improved by if the function $\mathtt{value}$ gets two additional parameters,
$\alpha$ and $\beta$.  The idea is that
\\[0.2cm]
\hspace*{1.3cm}
$\mathtt{valueAlphaBeta}(\mathtt{State}, \mathtt{player}, \mathtt{alpha}, \mathtt{beta})$
\\[0.2cm]
still computes the value of $\mathtt{State}$ as long as this value is strictly between $\alpha$ and $\beta$,
i.e.~we have
\\[0.2cm]
\hspace*{1.3cm}
$v = \mathtt{value}(\mathtt{State}, \mathtt{player}) \wedge \alpha < v \wedge v < \beta \rightarrow
 \mathtt{valueAlphaBeta}(\mathtt{State}, \mathtt{player}, \mathtt{alpha}, \mathtt{beta}) = v
$
\\[0.2cm]
However, if $v \leq \alpha$  the value returned by 
$\mathtt{valueAlphaBeta}$ is less than $\alpha$, while if $v \geq \beta$ it will be bigger than $\beta$.  The
idea is that if $v$ is outside the interval $[\alpha,  \beta]$, then we essentially do not care about the exact
value that is returned and, therefore, are able to shortcircuit the evaluation of the given $\mathtt{State}$.
This can result in significant speed improvements.  \myFig{game-alpha-beta.stlx} shows an implementation of the
function $\mathtt{valueAlphaBeta}$ that works along this line of thinking.


\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = 1,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    valueAlphaBeta := cachedProcedure(State, player, alpha := -1, beta := 1) {
        if (finished(State)) {
            return utility(State, player);
        }
        other  := arb(players() - { player });
        maxVal := -1;
        for (s in nextStates(State, player)) {
            val := -value(s, other, -beta, -alpha);
            if (val >= beta) {
                return val + 1/2; 
            }
            maxVal := max({val, maxVal});
        }
        return maxVal;
    };
\end{Verbatim}
\vspace*{-0.3cm}
\caption{$\alpha$-$\beta$-Pruning.}
\label{fig:game-alpha-beta.stlx}
\end{figure}

\begin{enumerate}
\item If $\mathtt{State}$ is a terminal state, the function returns the $\mathtt{utility}$ of the given
      $\mathtt{State}$ with respect to $\mathtt{player}$.
\item Otherwise, we iterate over all successor states $\mathtt{s} \in \mathtt{nextStates}(\mathtt{State},
  \mathtt{player})$.
\item As we want to find the successor state with the highest value, we initialize $\mathtt{maxVal}$ to $-1$
      since this is the lowest value that is possible and therefore $-1$ we have
      \\[0.2cm]
      \hspace*{1.3cm}
      $\max(v, -1) = v$ \quad for all values $v$ that can occur.
\item We have to recursively evaluate the state $\mathtt{s}$ for the $\mathtt{other}$ player.
      Since the value of a state for the $\mathtt{other}$ player is the negative of the value for
      $\mathtt{player}$, we have to exchange the roles of $\alpha$ and $\beta$.
\item As the specification of $\mathtt{valueAlphaBeta}$ ask us to compute the value of $\mathtt{State}$ only in
      case it is less than $\beta$, once we find a successor state $s$ that 
      If we find a value that is at least $\beta$ we can stop the evaluation

\end{enumerate}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "artificial-intelligence"
%%% End:
